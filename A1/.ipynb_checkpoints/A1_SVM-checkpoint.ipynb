{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris ##\n",
    "import os\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn import svm\n",
    "from tqdm._tqdm_notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41f5a0b2c30413993513fd9c1b573f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import landmarks\n",
    "import lab2_landmarks as l2\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    # Target Index from lab2_landmarks: 2 (Gender_label), 3 (Emotion_label)\n",
    "    return l2.extract_features_labels(2)\n",
    "    \n",
    "x, y = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape y\n",
    "yT = np.array([y, -(y - 1)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(x, yT, train_size = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn functions implementation\n",
    "\n",
    "def img_SVM(model, training_images, training_labels, test_images, test_labels):\n",
    "    classifier = model\n",
    "#     classifier = svm.SVC(kernel='linear')\n",
    "    classifier.fit(training_images, training_labels)\n",
    "\n",
    "    pred = classifier.predict(test_images)\n",
    "\n",
    "#     print(pred)\n",
    "#     print(\"Accuracy:\", accuracy_score(test_labels, pred))\n",
    "\n",
    "    return (pred, accuracy_score(test_labels, pred))\n",
    "\n",
    "\n",
    "def reshapeX(x):\n",
    "    return x.reshape((x.shape[0], x.shape[1] * x.shape[2]))\n",
    "\n",
    "def reshapeY(y):\n",
    "    return list(zip(*y))[0]\n",
    "\n",
    "x_tr = reshapeX(x_tr)\n",
    "x_te = reshapeX(x_te)\n",
    "y_tr = reshapeY(y_tr)\n",
    "y_te = reshapeY(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model instantiation\n",
    "models = []\n",
    "\n",
    "for c in [1, 10, 100]:\n",
    "    for degree in np.arange(2) + 2:\n",
    "        for gamma in ['scale', 'auto']:\n",
    "             for kernel in ['linear', 'rbf', 'poly']:\n",
    "                    models.append(svm.SVC(kernel = kernel, C = c, degree = degree, gamma = gamma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a27ad6674934768bf066829d981f335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=36), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run predictions\n",
    "results = []\n",
    "\n",
    "for model in tqdm_notebook(models):\n",
    "    results.append((model, img_SVM(model, x_tr, y_tr, x_te, y_te)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "basedir = os.getcwd()\n",
    "images_dir = basedir + '/datasets'\n",
    "\n",
    "labels_filename = 'labels.csv'\n",
    "\n",
    "def extract_features_labels():\n",
    "    \"\"\"\n",
    "    This function extracts the landmarks features for all images in the folder 'dataset/celeba'.\n",
    "    It also extracts the gender label for each image.\n",
    "    :return:\n",
    "        landmark_features:  an array containing 68 landmark points for each image in which a face was detected\n",
    "        emotion_labels:      an array containing the gender label (smiling=0 and notsmiling=1) for each image in\n",
    "                            which a face was detected\n",
    "    \"\"\"\n",
    "    image_paths = [os.path.join(images_dir, l) for l in os.listdir(images_dir) if l.endswith('.jpg')]\n",
    "    \n",
    "    target_size = None\n",
    "    labels_file = open(os.path.join(basedir, labels_filename), 'r')\n",
    "    #labels_file = open(os.path.join(basedir, labels), 'r')\n",
    "    \n",
    "    lines = labels_file.readlines()\n",
    "    \n",
    "    emotion_labels = {line.split('.')[0] : int(line.split('\\t')[2]) for line in lines[1:]}\n",
    "    #emotion_labels ={line.split('\\t')[0] : int(line.split('\\t')[3]) for line in lines[1:]}\n",
    "    if os.path.isdir(images_dir):\n",
    "        all_features = []\n",
    "        all_labels = []\n",
    "        for img_path in image_paths:\n",
    "            file_name= img_path.split('/')[-1].split('.')[0]\n",
    "            \n",
    "\n",
    "            # load image\n",
    "            img = image.img_to_array(\n",
    "                image.load_img(img_path,\n",
    "                               target_size=target_size,\n",
    "                               interpolation='bicubic'))\n",
    "            features, _ = run_dlib_shape(img)\n",
    "            if features is not None:\n",
    "                all_features.append(features)\n",
    "                all_labels.append(emotion_labels[file_name])\n",
    "\n",
    "    landmark_features = np.array(all_features)\n",
    "    emotion_labels = (np.array(all_labels) + 1)/2 # simply converts the -1 into 0, so smiling=0 and not smiling=1\n",
    "    \n",
    "    return landmark_features, emotion_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-1ae9147e58ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mextract_features_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-ff4a2fc97ad7>\u001b[0m in \u001b[0;36mextract_features_labels\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# load image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             img = image.img_to_array(\n\u001b[0m\u001b[1;32m     35\u001b[0m                 image.load_img(img_path,\n\u001b[1;32m     36\u001b[0m                                \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "extract_features_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris ##\n",
    "import os\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing lab2_landmarks\n",
    "basedir = '/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A1'\n",
    "directory = basedir.split('/')\n",
    "directory = '/'.join(directory[:-1])\n",
    "\n",
    "os.chdir(directory)\n",
    "\n",
    "import lab2_landmarks as l2\n",
    "\n",
    "# Editing lab2_landmarks attributes to change target folder\n",
    "l2.basedir = basedir\n",
    "l2.images_dir = basedir + '/datasets/'\n",
    "l2.labels_filename = 'labels.csv'\n",
    "\n",
    "# help(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = None\n",
    "y = None\n",
    "\n",
    "def get_data():\n",
    "    global x, y\n",
    "\n",
    "    x, y = l2.extract_features_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "extract_features_labels() missing 1 required positional argument: 'images_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c1be559af0b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-9023c9a13c03>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: extract_features_labels() missing 1 required positional argument: 'images_dir'"
     ]
    }
   ],
   "source": [
    "get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(l2.images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
