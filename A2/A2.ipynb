{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris ##\n",
    "import os\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "import glob\n",
    "import shutil\n",
    "import os.path\n",
    "import fnmatch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>smiling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.jpg</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.jpg</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.jpg</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4995</td>\n",
       "      <td>4995.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4996</td>\n",
       "      <td>4996.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4997</td>\n",
       "      <td>4997.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4998</td>\n",
       "      <td>4998.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4999</td>\n",
       "      <td>4999.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      img_name smiling\n",
       "0        0.jpg       1\n",
       "1        1.jpg       1\n",
       "2        2.jpg      -1\n",
       "3        3.jpg      -1\n",
       "4        4.jpg      -1\n",
       "...        ...     ...\n",
       "4995  4995.jpg       1\n",
       "4996  4996.jpg       1\n",
       "4997  4997.jpg       1\n",
       "4998  4998.jpg       1\n",
       "4999  4999.jpg       1\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/labels.csv\")\n",
    "df = pd.DataFrame(df).reset_index()\n",
    "df.columns = ['Index','Total']\n",
    "del df['Index']\n",
    "df[\"Index\"] = df[\"Total\"].str.split(\"\\t\").str[0]\n",
    "df[\"img_name\"] = df[\"Total\"].str.split(\"\\t\").str[1]\n",
    "#df[\"gender\"] = df[\"Total\"].str.split(\"\\t\").str[2]\n",
    "df[\"smiling\"] = df[\"Total\"].str.split(\"\\t\").str[3]\n",
    "del df['Total']\n",
    "del df['Index']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Smiling (1), Not Smiling (-1)\n",
    "\n",
    "celeb_smile = df.loc[df['smiling'] == '1']\n",
    "smile_img = celeb_smiling[['img_name']]\n",
    "smile_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "celeb_no_smile= df.loc[df['smiling'] == '-1']\n",
    "no_smile_img = celeb_not_smiling[['img_name']]\n",
    "no_smile_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir = \"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/img\"\n",
    "src = \"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/img\"\n",
    "#os.mkdir(\"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/img/smiling\")\n",
    "dst_smile = \"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/img/smiling\"\n",
    "\n",
    "names_smile = smile_img.img_name.tolist()\n",
    "\n",
    "for filename in os.listdir(src):\n",
    "    for name in names_smile:\n",
    "        if name == filename:\n",
    "             # move the file\n",
    "            shutil.move(\"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/img/\"+filename, dst_smile)\n",
    "            break\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/img/NotSmiling\")\n",
    "dst_no_smile = \"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/img/NotSmiling\"\n",
    "\n",
    "names_no_smile = no_smile_img.img_name.tolist()\n",
    "\n",
    "for filename in os.listdir(src):\n",
    "    for name in names_no_smile:\n",
    "        if name == filename:\n",
    "             # move the file\n",
    "            shutil.move(\"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/img/\"+filename, dst_no_smile)\n",
    "            break\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.mkdir(\"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/train\")\n",
    "#os.mkdir(\"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/train/smiling\")\n",
    "#os.mkdir(\"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/train/NotSmiling\")\n",
    "\n",
    "#os.mkdir(\"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/test\")\n",
    "#os.mkdir(\"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/test/smiling\")\n",
    "#os.mkdir(\"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/test/NotSmiling\")\n",
    "\n",
    "#os.mkdir(\"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/validation\")\n",
    "os.mkdir(\"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/validation/smiling\")\n",
    "os.mkdir(\"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/validation/NotSmiling\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images:  2500\n",
      "Training:  1750\n",
      "Validation:  375\n",
      "Testing:  375\n"
     ]
    }
   ],
   "source": [
    "os.chdir = \"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/img/smiling\"\n",
    "\n",
    "src_smile = \"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/img/smiling\"\n",
    "src_no_smile = \"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/img/Notsmiling\"\n",
    "\n",
    "allFileNames_smile = os.listdir(src_smile)\n",
    "np.random.shuffle(allFileNames_smile)\n",
    "train, valid, test = np.split(np.array(allFileNames_smile),[int(len(allFileNames_smile)*0.7), int(len(allFileNames_smile)*0.85)])\n",
    "\n",
    "train_smile = [src_smile+'/'+ name for name in train.tolist()]\n",
    "val_smile = [src_smile+'/' + name for name in valid.tolist()]\n",
    "test_smile = [src_smile+'/' + name for name in test.tolist()]\n",
    "\n",
    "print('Total images: ', len(allFileNames_smile))\n",
    "print('Training: ', len(train))\n",
    "print('Validation: ', len(valid))\n",
    "print('Testing: ', len(test))\n",
    "\n",
    "# Copy-pasting images\n",
    "for name in train_smile:\n",
    "    shutil.move(name, \"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/train/smiling\")\n",
    "\n",
    "for name in val_smile:\n",
    "    shutil.move(name, \"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/validation/smiling\")\n",
    "\n",
    "for name in test_smile:\n",
    "    shutil.move(name, \"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/train/smiling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images:  2500\n",
      "Training:  1750\n",
      "Validation:  375\n",
      "Testing:  375\n"
     ]
    }
   ],
   "source": [
    "os.chdir = \"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/img/Notsmiling\"\n",
    "\n",
    "src_smile = \"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/img/smiling\"\n",
    "src_no_smile = \"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/img/NotSmiling\"\n",
    "\n",
    "allFileNames_no_smile = os.listdir(src_no_smile)\n",
    "np.random.shuffle(allFileNames_no_smile)\n",
    "train, valid, test = np.split(np.array(allFileNames_no_smile),[int(len(allFileNames_no_smile)*0.7), int(len(allFileNames_no_smile)*0.85)])\n",
    "\n",
    "train_no_smile = [src_no_smile+'/'+ name for name in train.tolist()]\n",
    "val_no_smile = [src_no_smile+'/' + name for name in valid.tolist()]\n",
    "test_no_smile = [src_no_smile+'/' + name for name in test.tolist()]\n",
    "\n",
    "print('Total images: ', len(allFileNames_no_smile))\n",
    "print('Training: ', len(train))\n",
    "print('Validation: ', len(valid))\n",
    "print('Testing: ', len(test))\n",
    "\n",
    "# Copy-pasting images\n",
    "for name in train_no_smile:\n",
    "    shutil.move(name, \"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/train/NotSmiling\")\n",
    "\n",
    "for name in val_no_smile:\n",
    "    shutil.move(name, \"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/validation/NotSsmiling\")\n",
    "\n",
    "for name in test_no_smile:\n",
    "    shutil.move(name, \"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/train/NotSmiling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 106,082\n",
      "Trainable params: 105,954\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# starting point \n",
    "model_emotion= models.Sequential()\n",
    "\n",
    "# Add first convolutional block\n",
    "model_emotion.add(Conv2D(16, (3, 3), activation='relu', padding='same',input_shape=(128,128,3)))\n",
    "model_emotion.add(MaxPooling2D((2, 2), padding='same'))\n",
    "\n",
    "# second block\n",
    "model_emotion.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model_emotion.add(MaxPooling2D((2, 2), padding='same'))\n",
    "# third block\n",
    "model_emotion.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model_emotion.add(MaxPooling2D((2, 2), padding='same'))\n",
    "# fourth block\n",
    "model_emotion.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model_emotion.add(MaxPooling2D((2, 2), padding='same'))\n",
    "\n",
    "# global average pooling\n",
    "model_emotion.add(GlobalAveragePooling2D())\n",
    "# fully connected layer\n",
    "model_emotion.add(Dense(64, activation='relu'))\n",
    "model_emotion.add(BatchNormalization())\n",
    "# make predictions\n",
    "model_emotion.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "model_emotion.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use early stopping to optimally terminate training through callbacks\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "es=EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "\n",
    "# save best model automatically\n",
    "mc= ModelCheckpoint('/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/model_gender.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "cb_list=[es,mc]\n",
    "\n",
    "\n",
    "# compile model \n",
    "model_emotion.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.python.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4250 images belonging to 2 classes.\n",
      "Found 375 images belonging to 2 classes.\n",
      "Epoch 1/25\n",
      "132/132 [==============================] - 114s 862ms/step - loss: 0.6935 - accuracy: 0.5422 - val_loss: 0.5509 - val_accuracy: 0.9361\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.55092, saving model to /Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/model_gender.h5\n",
      "Epoch 2/25\n",
      "132/132 [==============================] - 124s 942ms/step - loss: 0.6800 - accuracy: 0.5743 - val_loss: 0.3813 - val_accuracy: 0.8950\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.55092 to 0.38134, saving model to /Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/model_gender.h5\n",
      "Epoch 3/25\n",
      "132/132 [==============================] - 115s 871ms/step - loss: 0.6640 - accuracy: 0.6040 - val_loss: 0.7038 - val_accuracy: 0.4708\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.38134\n",
      "Epoch 4/25\n",
      " 61/132 [============>.................] - ETA: 1:23 - loss: 0.6217 - accuracy: 0.6662"
     ]
    }
   ],
   "source": [
    "# set up data generator\n",
    "data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# get batches of training images from the directory\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "        '/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/train',\n",
    "        target_size=(128, 128),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# get batches of validation images from the directory\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "        '/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/A2/celeba/validation',\n",
    "        target_size=(128, 128),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "history = model_emotion.fit_generator(\n",
    "        train_generator,\n",
    "        epochs=25,\n",
    "        steps_per_epoch=train_generator.samples // 32,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_generator.samples // 32,\n",
    "        callbacks=cb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
