{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris ##\n",
    "import os\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn import svm\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = (\"/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/B2\")\n",
    "os.chdir(base_dir)\n",
    "\n",
    "dataset_dir = os.path.join(base_dir, 'img')\n",
    "labels_filename = os.path.join(base_dir, 'labels.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>eyecolour_label</th>\n",
       "      <th>eye_colour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.png</td>\n",
       "      <td>1</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.png</td>\n",
       "      <td>2</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.png</td>\n",
       "      <td>2</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.png</td>\n",
       "      <td>2</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.png</td>\n",
       "      <td>0</td>\n",
       "      <td>Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9995</td>\n",
       "      <td>9995.png</td>\n",
       "      <td>3</td>\n",
       "      <td>Gray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>9996.png</td>\n",
       "      <td>0</td>\n",
       "      <td>Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>9997.png</td>\n",
       "      <td>1</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>9998.png</td>\n",
       "      <td>0</td>\n",
       "      <td>Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>9999.png</td>\n",
       "      <td>2</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     file_name eyecolour_label eye_colour\n",
       "0        0.png               1       Blue\n",
       "1        1.png               2      Green\n",
       "2        2.png               2      Green\n",
       "3        3.png               2      Green\n",
       "4        4.png               0      Brown\n",
       "...        ...             ...        ...\n",
       "9995  9995.png               3       Gray\n",
       "9996  9996.png               0      Brown\n",
       "9997  9997.png               1       Blue\n",
       "9998  9998.png               0      Brown\n",
       "9999  9999.png               2      Green\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(labels_filename)\n",
    "df.columns=['original']\n",
    "df[\"file_name\"] = df['original'].str.split(\"\\t\").str[3]\n",
    "df[\"eyecolour_label\"] = df['original'].str.split(\"\\t\").str[1]\n",
    "del df['original']\n",
    "    \n",
    "eye_colour = []\n",
    "    \n",
    "for eye in df.eyecolour_label:\n",
    "    if eye == '0':\n",
    "        eye_colour.append(\"Brown\")\n",
    "    elif eye == '1':\n",
    "        eye_colour.append(\"Blue\")\n",
    "    elif eye == '2':\n",
    "        eye_colour.append(\"Green\")\n",
    "    elif eye == '3':\n",
    "        eye_colour.append(\"Gray\")\n",
    "    else:\n",
    "        eye_colour.append(\"Black\")\n",
    "    \n",
    "df['eye_colour'] = eye_colour\n",
    "    \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras import models\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import adam\n",
    "from tensorflow.python.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Preparataion\n",
      "Found 5625 validated image filenames belonging to 5 classes.\n",
      "\n",
      "Validation Dataset Preparataion\n",
      "Found 1875 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data, test_data = train_test_split(df, random_state=0)\n",
    "    \n",
    "# Setup the data generator\n",
    "data_generator = ImageDataGenerator(\n",
    "    rescale = 1./255.,\n",
    "    validation_split = 0.25,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    "    \n",
    ")\n",
    "    \n",
    "# Get batches of training dataset from the dataframe\n",
    "print(\"Training Dataset Preparataion\")\n",
    "train_generator = data_generator.flow_from_dataframe(\n",
    "        dataframe = train_data, directory = dataset_dir,\n",
    "        x_col = \"file_name\", y_col = \"eyecolour_label\",\n",
    "        class_mode = 'categorical', target_size = (30,30),\n",
    "        batch_size = 32, subset = 'training')\n",
    "    \n",
    "    # Get batches of validation dataset from the dataframe\n",
    "print(\"\\nValidation Dataset Preparataion\")\n",
    "validation_generator = data_generator.flow_from_dataframe(\n",
    "        dataframe = train_data, directory = dataset_dir,\n",
    "        x_col = \"file_name\", y_col = \"eyecolour_label\",\n",
    "        class_mode = 'categorical', target_size = (30,30),\n",
    "        batch_size = 32, subset = 'validation')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 24)        672       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 15, 15, 24)        5208      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 48)        10416     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 15, 15, 96)        41568     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 96)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6144)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 30725     \n",
      "=================================================================\n",
      "Total params: 88,589\n",
      "Trainable params: 88,589\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# starting point \n",
    "model= models.Sequential()\n",
    "\n",
    "# Add first convolutional block\n",
    "model.add(Conv2D(24, (3, 3), activation='relu', padding='same',input_shape=(30,30,3)))\n",
    "model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "\n",
    "# second block\n",
    "model.add(Conv2D(24, (3, 3), activation='relu', padding='same'))\n",
    "#model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "# third block\n",
    "model.add(Conv2D(48, (3, 3), activation='relu', padding='same'))\n",
    "#model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "# fourth block\n",
    "model.add(Conv2D(96, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "\n",
    "# global average pooling\n",
    "#model.add(GlobalAveragePooling2D())\n",
    "# fully connected layer\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "# make predictions\n",
    "model.add(Flatten())\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use early stopping to optimally terminate training through callbacks\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "es=EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "\n",
    "# save best model automatically\n",
    "mc= ModelCheckpoint('/Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/B1/model_B1.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "cb_list=[es,mc]\n",
    "\n",
    "\n",
    "# compile model \n",
    "optimizer = optimizers.Adam(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "175/175 [==============================] - 70s 399ms/step - loss: 1.6105 - accuracy: 0.1954 - val_loss: 1.6109 - val_accuracy: 0.1923\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.61089, saving model to /Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/B1/model_B1.h5\n",
      "Epoch 2/25\n",
      "175/175 [==============================] - 72s 414ms/step - loss: 1.6097 - accuracy: 0.1995 - val_loss: 1.6087 - val_accuracy: 0.1877\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.61089 to 1.60867, saving model to /Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/B1/model_B1.h5\n",
      "Epoch 3/25\n",
      "175/175 [==============================] - 71s 407ms/step - loss: 1.6096 - accuracy: 0.1986 - val_loss: 1.6085 - val_accuracy: 0.1926\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.60867 to 1.60851, saving model to /Users/Hyunjee/Desktop/AMLS_19-20_SN16075203/B1/model_B1.h5\n",
      "Epoch 4/25\n",
      "175/175 [==============================] - 67s 382ms/step - loss: 1.6096 - accuracy: 0.1958 - val_loss: 1.6092 - val_accuracy: 0.1948\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.60851\n",
      "Epoch 5/25\n",
      "175/175 [==============================] - 67s 381ms/step - loss: 1.6097 - accuracy: 0.2028 - val_loss: 1.6097 - val_accuracy: 0.1894\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.60851\n",
      "Epoch 6/25\n",
      "175/175 [==============================] - 67s 385ms/step - loss: 1.6095 - accuracy: 0.2033 - val_loss: 1.6112 - val_accuracy: 0.1970\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.60851\n",
      "Epoch 7/25\n",
      "175/175 [==============================] - 65s 372ms/step - loss: 1.6109 - accuracy: 0.2005 - val_loss: 1.6097 - val_accuracy: 0.1883\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.60851\n",
      "Epoch 8/25\n",
      "175/175 [==============================] - 65s 371ms/step - loss: 1.6095 - accuracy: 0.2053 - val_loss: 1.6113 - val_accuracy: 0.1991\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.60851\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        epochs=25,\n",
    "        steps_per_epoch=train_generator.samples // 32,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_generator.samples // 32,\n",
    "        callbacks=cb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training and validation accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.ylim([.5,1.1])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.savefig(\"model_gender.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
